# @package _global_

task: classification

# Settings for Policy Model that searches augmentation policies.
policy_model:

  # Number of augmentation sub-policies. When an image passes through an augmentation pipeline, Faster AutoAugment
  # randomly chooses one sub-policy and uses augmentations from that sub-policy to transform an input image. A larger
  # number of sub-policies leads to a more diverse set of augmentations and better performance of a model trained on
  # augmented images. However, an increase in the number of sub-policies leads to the exponential growth of a search
  # space of augmentations, so you need more training data for Policy Model to find good augmentation policies.
  num_sub_policies: 100

  # Number of chunks in a batch. Faster AutoAugment splits each batch of images into `num_chunks` chunks. Then it
  # applies the same sub-policy with the same parameters to each image in a chunk. This parameter controls the tradeoff
  # between the speed of augmentation search and diversity of augmentations. Larger `num_chunks` values will lead to
  # faster searching but less diverse set of augmentations. Note that this parameter is used only in the searching
  # phase. When you train a model with found sub-policies, Albumentations will apply a distinct set of transformations
  # to each image separately.
  num_chunks: 8

  # Number of consecutive augmentations in each sub-policy. Faster AutoAugment will sequentially apply `operation_count`
  # augmentations from a sub-policy to an image. Larger values of `operation_count` lead to better performance of
  # a model trained on augmented images. Simultaneously, larger values of `operation_count` affect the speed of search
  # and increase the searching time.
  operation_count: 4

# Settings for Classification Model that is used for two purposes:
# 1. As a model that performs classification of input images.
# 2. As a Discriminator for Policy Model.
classification_model:
  # A custom classification model is used. This model is defined inside the `model.py` file which is located
  # in the same directory with `search.yaml` and `dataset.py`.
  _target_: model.Cifar10ClassificationModel

  #  # As an alternative, you could use a built-in AutoAlbument model using the following config:
  #  #  _target_: autoalbument.faster_autoaugment.models.ClassificationModel
  #
  #  # Number of classes in the dataset. The dataset implementation should return an integer in the range
  #  # [0, num_classes - 1] as a class label of an image.
  #  num_classes: 10
  #
  #  # The architecture of Classification Model. AutoAlbument uses models from
  #  # https://github.com/rwightman/pytorch-image-models/. Please refer to its documentation to get a list of available
  #  # models - https://rwightman.github.io/pytorch-image-models/#list-models-with-pretrained-weights.
  #  architecture: resnet18
  #
  #  # Boolean flag that indicates whether the selected model architecture should load pretrained weights or use randomly
  #  # initialized weights.
  #  pretrained: False

data:
  # Class for the PyTorch Dataset and arguments to it. AutoAlbument will create an object of this class using
  # the `instantiate` method from Hydra - https://hydra.cc/docs/next/patterns/instantiate_objects/overview/.
  #
  # Note that the target class value in the `_target_` argument should be located inside PYTHONPATH so Hydra could
  # find it. The directory with the config file is automatically added to PYTHONPATH, so the default value
  # `dataset.SearchDataset` points to the class `SearchDataset` from the `dataset.py` file. This `dataset.py` file is
  # located along with the `search.yaml` file in the same directory provided by `--config-dir`.
  #
  # As an alternative, you could provide a path to a Python file with the dataset using the `dataset_file` parameter
  # instead of the `dataset` parameter. The Python file should contain the implementation of a PyTorch dataset for
  # augmentation search. The dataset class should have named `SearchDataset`. The value in `dataset_file` could either
  # be a relative or an absolute path ; in the case of a relative path, the path should be relative to this config
  # file's location.
  #
  # - Example of a relative path:
  # dataset_file: dataset.py
  #
  # - Example of an absolute path:
  # dataset_file: /projects/pytorch/dataset.py
  #
  dataset:
    _target_: dataset.Cifar10SearchDataset
    root: "~/data/cifar10"
    train: True
    download: True

  # Normalization values for images. For each image, the search pipeline will subtract `mean` and divide by `std`.
  # Normalization is applied after transforms defined in `preprocessing`. Note that regardless of `input_dtype`,
  # the normalization function will always receive a `float32` input with values in the range [0.0, 1.0], so you should
  # define `mean` and `std` values accordingly.
  normalization:
    mean: [0.4914, 0.4822, 0.4465]
    std: [0.247, 0.243, 0.261]

  # Parameters for the PyTorch DataLoader. Please refer to the PyTorch documentation for the description of parameters -
  # https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader.
  dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 128
    shuffle: True
    num_workers: 8
    pin_memory: True
    drop_last: True
